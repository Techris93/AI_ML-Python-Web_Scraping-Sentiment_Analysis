{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d729dbf-02ea-4f96-986a-b972471525b0",
   "metadata": {},
   "source": [
    "# AI/ML with Python: Web Scraping & Sentiment Analysis\n",
    "## Sentiment Analysis Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925de708-58fc-4f66-a5a4-609124a7b4f6",
   "metadata": {},
   "source": [
    "### Introduction to VADER\n",
    "\n",
    "We will start off by importing `nltk` (Natural Language Toolkit) which allows us utilise its internal package `SentimentIntensityAnalyzer` that will provide us with the necessary polarity scores in terms of negative, neutral, or positive. To start, ensure that you have `ntlk` installed on your local machine. If you haven't, open your terminal and do `pip install nltk` as shown below.\n",
    "\n",
    "After importing `nltk`, ensure that you have `vader_lexicon` downloaded. Once everything is completed, we will proceed to import `SentimentIntensityAnalyzer` as a package from `nltk.sentiment`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbfbc1d4-bfdc-4ddc-b553-a5ec2d8c4dfe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting click (from nltk)\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting joblib (from nltk)\n",
      "  Using cached joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Downloading regex-2023.12.25-cp311-cp311-macosx_10_9_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m777.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tqdm (from nltk)\n",
      "  Downloading tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2023.12.25-cp311-cp311-macosx_10_9_x86_64.whl (296 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.5/296.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "Downloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tqdm, regex, joblib, click, nltk\n",
      "Successfully installed click-8.1.7 joblib-1.3.2 nltk-3.8.1 regex-2023.12.25 tqdm-4.66.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "086eb7ad-1513-4399-8edd-d63563f685df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02869e55-99c9-489e-be21-61f4c59224f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/chrixchange/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "717defa8-bd76-44a7-9416-e6a09e4a4f6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdd015c-a791-4bb0-b0c7-1efa4e48d874",
   "metadata": {},
   "source": [
    "With our setup complete, we're now equipped to analyze the sentiment of various sentences. We will utilize the `polarity_scores` method to evaluate and display their sentiment metrics. Proceed with executing the following code to observe the breakdown of sentiment scores for each sentence provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "539cb8f1-e984-4c66-9fd2-f10112e7f4cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: I love this product, it's absolutely amazing!\n",
      "Scores: {'neg': 0.0, 'neu': 0.318, 'pos': 0.682, 'compound': 0.862}\n",
      "\n",
      "Text: This is the worst movie I have ever seen.\n",
      "Scores: {'neg': 0.369, 'neu': 0.631, 'pos': 0.0, 'compound': -0.6249}\n",
      "\n",
      "Text: I'm not sure how I feel about this new policy.\n",
      "Scores: {'neg': 0.197, 'neu': 0.803, 'pos': 0.0, 'compound': -0.2411}\n",
      "\n",
      "Text: Meh, it was okay, nothing special.\n",
      "Scores: {'neg': 0.421, 'neu': 0.355, 'pos': 0.225, 'compound': -0.1675}\n",
      "\n",
      "Text: Wow, this new update is fantastic! 😊\n",
      "Scores: {'neg': 0.0, 'neu': 0.342, 'pos': 0.658, 'compound': 0.8268}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sample texts that we will be using for sentiment analysis\n",
    "texts = [\n",
    "    \"I love this product, it's absolutely amazing!\",\n",
    "    \"This is the worst movie I have ever seen.\",\n",
    "    \"I'm not sure how I feel about this new policy.\",\n",
    "    \"Meh, it was okay, nothing special.\",\n",
    "    \"Wow, this new update is fantastic! 😊\"\n",
    "]\n",
    "\n",
    "for text in texts:\n",
    "    scores = sia.polarity_scores(text)\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Scores: {scores}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59993ea0-bd28-4d85-b9d3-82caa793e482",
   "metadata": {},
   "source": [
    "The `polarity_scores` method from `SentimentIntensityAnalyzer` in VADER is a function that <b>computes sentiment scores</b> for a given piece of text. When you pass text to this method, it returns a dictionary with <b>four different scores</b> that quantify the sentiment of the text. The score breaks down into four different aspects, each being negative, neutral, positive and compound. Here is a breakdown of what each of them mean:\n",
    "\n",
    "<b>Negative:</b> This score indicates the proportion of the text that carries a negative sentiment. The value ranges from 0 to 1, where higher values correspond to negative sentiment.\n",
    "\n",
    "<b>Neutral:</b> This score represents the proportion of the text that is considered neutral (lacking positive or negative sentiment). Like the negative score, this also ranges from 0 to 1.\n",
    "\n",
    "<b>Positive:</b> This score reflects the proportion of the text that conveys a positive sentiment. It is also a value between 0 and 1, with higher values denoting stronger positive sentiment.\n",
    "\n",
    "<b>Compound:</b> The compound score is a composite score that calculates the sum of the positive, negative, and neutral scores, which is then normalized between -1 (most extreme negative) and +1 (most extreme positive). This score attempts to represent the overall sentiment of the text in a single number.\n",
    "\n",
    "From this example, you can see how text and sentences are quantified based on how negative or positive they are. Feel free to try it out with some of your own sentences, and see its results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ed6569a-0106-4e02-bef8-bf7ecf91e496",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0, 'neu': 0.513, 'pos': 0.487, 'compound': 0.431}\n"
     ]
    }
   ],
   "source": [
    "text = \" You don't look bad\"\n",
    "\n",
    "score = sia.polarity_scores(text)\n",
    "print(f\"{score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec24d51d-2cde-4a13-8287-41f746fdd5bb",
   "metadata": {},
   "source": [
    "### Introduction to AFINN\n",
    "\n",
    "To begin, AFINN uses a Valence Score Assignment where each word in the AFINN lexicon has been manually rated by humans for sentiment strength. For example, the word \"happy\" might have a positive valence of 3, while \"sad\" has a negative valence of -2. To calculate its sentiments,  a sentiment analysis algorithm will look up each word in the AFINN lexicon when processing the text. If the word exists in the lexicon, its valence score will contribute to the total sentiment score of the text.\n",
    "\n",
    "The total sentiment score of a piece of text is calculated by summing the valence scores of all sentiment-bearing words found in the lexicon. The sum can be normalized or adjusted based on the length of the text to provide an average sentiment score per term if desired. Before we start coding, ensure that you have afinn installed via your local terminal. Then, proceed to import 'Afinn' from afinn and assign it to afinn, as seen in the example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72371704-de46-4a7b-81f5-b27e47773349",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting afinn\n",
      "  Downloading afinn-0.1.tar.gz (52 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.6/52.6 kB\u001b[0m \u001b[31m467.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m648.8 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: afinn\n",
      "  Building wheel for afinn (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for afinn: filename=afinn-0.1-py3-none-any.whl size=53429 sha256=b9b50ba748bb2f4a442a7b9ba74ee316950bee4914927013fe192d6746e78cdd\n",
      "  Stored in directory: /Users/chrixchange/Library/Caches/pip/wheels/ee/d3/a0/f9255ebac29886acb1c28b35b37523f6399677fa06be379f25\n",
      "Successfully built afinn\n",
      "Installing collected packages: afinn\n",
      "Successfully installed afinn-0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install afinn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce7098f1-d93e-4d95-82a3-df9a84d4acaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from afinn import Afinn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92a50a26-a845-4b9b-9819-9bfc0ebb084c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We initialize Afinn sentiment analyzer\n",
    "afinn = Afinn()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9616351c-331b-47a2-b0ac-af98324dfca4",
   "metadata": {},
   "source": [
    "Now, let's move on to examining a series of texts. We'll apply our analysis and you'll notice that each word is assigned a score from -5 to +5. However, the cumulative score for an entire sentence may exceed this range, as it represents the sum of the individual scores for all words contained in that sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9c0ba4f-5652-401b-9827-6d727f60d0fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: I really love the new design of your website!\n",
      "Score: 3.0\n",
      "\n",
      "Text: I hate waiting in long queues.\n",
      "Score: -3.0\n",
      "\n",
      "Text: This is utterly fantastic!\n",
      "Score: 4.0\n",
      "\n",
      "Text: It's raining again. This weather is depressing.\n",
      "Score: -2.0\n",
      "\n",
      "Text: I'm not sure how I feel about the new policy.\n",
      "Score: 0.0\n",
      "\n",
      "Text: I love the absolutely wonderful performance, it was simply perfect and made me incredibly happy!\n",
      "Score: 13.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List of sentences to analyze\n",
    "texts = [\n",
    "    \"I really love the new design of your website!\",\n",
    "    \"I hate waiting in long queues.\",\n",
    "    \"This is utterly fantastic!\",\n",
    "    \"It's raining again. This weather is depressing.\",\n",
    "    \"I'm not sure how I feel about the new policy.\",\n",
    "    \"I love the absolutely wonderful performance, it was simply perfect and made me incredibly happy!\"\n",
    "]\n",
    "\n",
    "# Analyze the sentiment of each sentence\n",
    "for text in texts:\n",
    "    score = afinn.score(text)\n",
    "    print(f\"Text: {text}\\nScore: {score}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ca3cdb-e24d-43aa-89eb-19cdfdf40f13",
   "metadata": {},
   "source": [
    "The <b>sentiment score</b> of a piece of text—such as a sentence or an entire document—is calculated by <b>summing the scores of all words</b> that appear in the text and are also present in the AFINN lexicon. In the case where a sentence has words not found in the AFINN lexicon, those words simply do not contribute to the score. \n",
    "\n",
    "The final score reflects the overall sentiment as quantified by the lexicon, with higher positive scores indicating more positive sentiment, scores around zero indicating neutrality, and negative scores indicating negative sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d09e80f-dad8-4645-ad11-8580cc18a85a",
   "metadata": {},
   "source": [
    "## Sentiment Analysis with Naive Bayes Classifier\n",
    "\n",
    "The objective of this exercise will be to build a Naive Bayes model that can classify text samples into either positive or negative sentiments. In this exercise, we'll be using an inbuilt dataset \"movie_reviews\" within the `nltk` library. As usual, ensure that you have the `nltk` and `scikit-learn` libraries installed. When you are done, proceed to import the following packages: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "374b61e9-73a6-429b-91ec-971abaeae07a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.3.2-cp311-cp311-macosx_10_9_x86_64.whl.metadata (11 kB)\n",
      "Collecting numpy<2.0,>=1.17.3 (from scikit-learn)\n",
      "  Downloading numpy-1.26.2-cp311-cp311-macosx_10_9_x86_64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m580.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m897.9 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting scipy>=1.5.0 (from scikit-learn)\n",
      "  Downloading scipy-1.11.4-cp311-cp311-macosx_10_9_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: joblib>=1.1.1 in ./lib/python3.11/site-packages (from scikit-learn) (1.3.2)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.2.0-py3-none-any.whl.metadata (10.0 kB)\n",
      "Downloading scikit_learn-1.3.2-cp311-cp311-macosx_10_9_x86_64.whl (10.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.2-cp311-cp311-macosx_10_9_x86_64.whl (20.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.6/20.6 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.11.4-cp311-cp311-macosx_10_9_x86_64.whl (37.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.2/37.2 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: threadpoolctl, numpy, scipy, scikit-learn\n",
      "Successfully installed numpy-1.26.2 scikit-learn-1.3.2 scipy-1.11.4 threadpoolctl-3.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b5899a9-bbc1-486d-a0bf-cc06593b448d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import movie_reviews\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3eaf8c-a67c-48a2-babb-aba5964f448e",
   "metadata": {},
   "source": [
    "Now that we have imported all the packages, we can proceed to download the <b>movie_reviews</b> dataset from the `nltk` library, which is a collection of movie reviews that have been categorized as either positive or negative. \n",
    "\n",
    "It contains 2,000 movie reviews, with an equal number of positive and negative reviews. This balanced dataset is ideal for training and testing sentiment analysis algorithms, specifically the Naive Bayes Classifiers in this case to determine whether a new movie review is positive or negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e23a3ab-6526-48be-9111-537dde2f01c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     /Users/chrixchange/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the movie review dataset from nltk\n",
    "nltk.download('movie_reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d9b7119-cd3e-4c8b-a082-b59c8ce17e24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run the below code to load the reviews and text preprocessing the data for modeling\n",
    "documents = [(\" \".join(movie_reviews.words(fileid)), category)\n",
    "             for category in movie_reviews.categories()\n",
    "             for fileid in movie_reviews.fileids(category)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "790bb605-1875-4ea0-8e90-e9a771629910",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split the dataset into the text and labels\n",
    "texts, labels = zip(*documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ef7cda8-dffa-44c4-bfa2-09f9e07fb305",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The handle_negation function is designed to preprocess text to better handle negations when performing sentiment analysis. \n",
    "# Negation words like \"not,\" \"no,\" \"never,\" and \"cannot\" can completely change the sentiment of the phrase that follows them. \n",
    "def handle_negation(text):\n",
    "    # A simple way to handle negation: attach \"not_\" to words following a negation word\n",
    "    negation_re = re.compile(r\"\\b(not|no|never|cannot)\\b[\\s]+([a-z]+)\", re.IGNORECASE)\n",
    "    return negation_re.sub(lambda match: f\"{match.group(1)}_{match.group(2)}\", text)\n",
    "\n",
    "# Apply the negation handling to your texts\n",
    "texts = [handle_negation(text) for text in texts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "411b8ac7-e9a6-4bda-aa98-f1a85f2fdef9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This flattens a list of lists (or a mix of lists and strings) into a list of strings, needed for text processing tasks such as vectorization\n",
    "texts = [' '.join(text) if isinstance(text, list) else text for text in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa647f0-db31-4d43-8d63-e27f6e3a90c5",
   "metadata": {},
   "source": [
    "Like what we have covered in our past campaign: NLP with Python, the above steps simply cleans and processes the data for trainng. It separates the dataset into both texts and its associated labels (either positive or negative). \n",
    "\n",
    "With that in place, we can utilise the prelabeled data `labels` and `texts` to train our model. Our next step would be preprocessing and feature extraction, a critical step that help transform raw text data into a structured format that a machine learning model can understand and learn from. Run the following code to see it in action!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "43d2310b-ac6e-48ea-afb5-4ad7c972b432",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(texts, labels, test_size=0.25, random_state=42)\n",
    "\n",
    "# Initialize a CountVectorizer for text vectorization\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 2))\n",
    "\n",
    "# Fit and transform the training data\n",
    "train_vectors = vectorizer.fit_transform(train_texts)\n",
    "\n",
    "# Transform the test data\n",
    "test_vectors = vectorizer.transform(test_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5420620e-404b-469e-9d15-376c91cd4e2a",
   "metadata": {},
   "source": [
    "We split the data into 2 parts: training and testing data. `train_texts` will contain the texts that will be used for training the machine learning model. `test_texts` will contain the texts that will be used for testing the model's performance, while `train_labels` and `test_labels` will hold the corresponding labels for the training and testing texts. `train_test_split()` will be the function that performs the split of the dataset into both training and test sets.\n",
    "\n",
    "The test_size signaling 0.25 suggests that 25% will be used for testing and the remaining 75% will be used for training. Setting a random seed will be used for experimental consistency, ensuring that every time we run this code with the same input data and random_state, we will get the exact same split.\n",
    "\n",
    "Initialising `CountVectorizer` creates a feature extraction method from the scikit-learn library that converts a collection of text documents into a matrix of token counts, which turns raw text into features that we can feed into the machine learning model. \n",
    "\n",
    "As covered previously, we can see the N-grams in action, where `ngram_range=(1,2)` means the first element of the tuple, 1, implies that the minimum size of n-grams will be 1, which includes single words. The second element of the tuple, 2, means that the maximum size of n-grams will be 2, which includes pairs of consecutive words.\n",
    "\n",
    "The fit method `fit_transform` then learns the vocabulary of the training data. It decides what tokens (words, symbols, etc.) will be considered in the text representation. After fitting, the vectorizer has a mapping from word tokens found in the training data to feature indices. We then proceed to `transform` the text into a numerical representation, a sparse matrix where each row corresponds to a document, and each column represents a token from the vocabulary. With the features extracted, we will proceed next to pass them into the classifiers.\n",
    "\n",
    "We will initialize the Multinomial Naive Bayes Classifier that we imported earlier and assign it as a classifier. Over here, we will then use the inbuilt fit function to train the model using both training data and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "575e8fff-6014-4a60-9730-76fdfca8bbf6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the Multinomial Naive Bayes classifier\n",
    "classifier = MultinomialNB()\n",
    "\n",
    "# Train the classifier\n",
    "classifier.fit(train_vectors, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bc8c14-8019-44e1-8b25-73a15b1a6951",
   "metadata": {},
   "source": [
    "By taking in both the `train_vector` (the matrix) and `train_labels` (label containing \"positive\", \"negative\" or \"neutral\"), the classifier learns the probability of each word given each label. This is done by counting the frequency of each word in documents with each label, and then calculating the likelihood of the word occurring in each class.\n",
    "\n",
    "Once trained, the classifier can then be used to predict the sentiment labels of new, unseen texts by calling the predict method, as you will see in the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9547f8fe-3de4-404f-8c14-cafa798464c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8180\n"
     ]
    }
   ],
   "source": [
    "# Predict sentiments for test data\n",
    "predictions = classifier.predict(test_vectors)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(test_labels, predictions)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb47b65-e734-44f3-b17e-09eb8c05553c",
   "metadata": {},
   "source": [
    "`accuracy_score` will then calculate the accuracy of the predictions. Accuracy is a common metric for classification tasks and is defined as the proportion of true results (both true positives and true negatives) among the total number of cases examined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d8291ab-f75f-4219-a183-a089cb9d0e4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentiment predicted by the model is: pos\n"
     ]
    }
   ],
   "source": [
    "# Function to predict sentiment of a new review\n",
    "def predict_sentiment(new_text):\n",
    "    new_vector = vectorizer.transform([new_text])\n",
    "    pred = classifier.predict(new_vector)\n",
    "    return pred[0]\n",
    "\n",
    "# Test the function\n",
    "sample_review = \"I absolutely loved this movie, the storyline was engaging from start to finish!\"\n",
    "print(f\"The sentiment predicted by the model is: {predict_sentiment(sample_review)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab49279-ebac-46cf-8848-9bee04f1da8e",
   "metadata": {},
   "source": [
    "Great! With our trained classifier ready, we have the capability to evaluate new reviews. The function `predict_sentiment` was crafted to convert any given text into a numerical format akin to the transformation applied to our training dataset. This numerical data is then presented to the trained classifier, which yields a sentiment prediction. From the example provided, the classifier was presented with an upbeat movie review, and it accurately returned the sentiment as positive.\n",
    "\n",
    "However, it is important to remember that no model is perfect, and there will always be some instances where predictions are incorrect.  Naive Bayes is a simple probabilistic classifier that doesn’t understand context or word order; it only looks at word frequencies. \n",
    "\n",
    "It can’t capture the meaning of phrases as a whole, which can lead to incorrect classifications at times as well. So, don't be surprised if you put in some inputs and it generates a wrong outcome. Ultimately it's trained on 2000 words (1000 pos and 1000 neg), so a much larger dataset is needed for a greater level of accuracy. Therefore, understanding and improving upon these errors is a key part of the machine-learning process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae057a9-7e33-44c3-9a79-d962236c856a",
   "metadata": {},
   "source": [
    "### Sentiment Analysis with Logistic Regression\n",
    "\n",
    "Similar to the the Naive Bayes model, we will now do prediction with the Logistic Regression model using the same dataset. Unlike Naive Bayes, logistic regression incorporates a different kind of feature weighting, like TF-IDF in this case, which can improve performance by highlighting important words.\n",
    "\n",
    "We will also utilise N-grams to make the prediction more accurate. Like Naive Bayes, we initialise the `LogisticRegression()` function, and just like how we did it for Naive Bayes model, we will fit it to the model before we use it for prediction. Let's check it out below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "54058a61-7d88-4524-af68-f88a32326086",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.8320\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Use TF-IDF Vectorization instead of simple counts\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 3), min_df=5, max_df=0.8)\n",
    "train_vectors = vectorizer.fit_transform(train_texts)\n",
    "test_vectors = vectorizer.transform(test_texts)\n",
    "\n",
    "# Initialize the Logistic Regression classifier\n",
    "logistic_classifier = LogisticRegression()\n",
    "\n",
    "# Train the classifier on the training data and labels\n",
    "logistic_classifier.fit(train_vectors, train_labels)\n",
    "\n",
    "# Predict sentiments for test data using the trained classifier\n",
    "logistic_predictions = logistic_classifier.predict(test_vectors)\n",
    "\n",
    "# Calculate accuracy of the classifier on the test data\n",
    "logistic_accuracy = accuracy_score(test_labels, logistic_predictions)\n",
    "\n",
    "print(f\"Logistic Regression Accuracy: {logistic_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30da749a-5e89-429b-8a86-57a8cbba15bb",
   "metadata": {},
   "source": [
    "With the model trained, we go on next to make predictions with sample texts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "053c2899-14e7-42a4-ae2f-f41e0bd3f55d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentiment predicted by the model is: pos\n"
     ]
    }
   ],
   "source": [
    "# Function to predict sentiment of a new review\n",
    "def logistic_predict_sentiment(new_text):\n",
    "    new_vector = vectorizer.transform([new_text])\n",
    "    pred = logistic_classifier.predict(new_vector)\n",
    "    return pred[0]\n",
    "\n",
    "# Test the function\n",
    "sample_review = \"The sun is shining and I'm so absolutely happy today!\"\n",
    "print(f\"The sentiment predicted by the model is: {logistic_predict_sentiment(sample_review)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85c51be-ca72-47bb-8fa9-068d5da1d20e",
   "metadata": {},
   "source": [
    "If you are wondering how the models decide on where the sample text is positive or negative, the code below shows what is happening under the hood. It showcases the prediction probability of the sample text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e2e30a52-a4f3-4625-8227-cc126a3875ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction probability for the sample text:  [[0.48429751 0.51570249]]\n"
     ]
    }
   ],
   "source": [
    "# Check the prediction probability for a sample text\n",
    "sample_prob = logistic_classifier.predict_proba(vectorizer.transform([sample_review]))\n",
    "print(\"Prediction probability for the sample text: \", sample_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061f17e5-9518-47d9-abd6-12166bbdb3ce",
   "metadata": {},
   "source": [
    "The probability on the left represent negative sentiment while the right positive sentiment. The larger probability will result in whichever sentiment being reflected, as simple as that!\n",
    "\n",
    "With that, we come to the end and it's time to prepare your submission!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025c7639-10bf-416d-8c5f-ce63f68bfbdb",
   "metadata": {},
   "source": [
    "## Submission Deliverable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "96ce7065-5b70-4a7e-ad28-2b28da704630",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     /Users/chrixchange/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/twitter_samples.zip.\n"
     ]
    }
   ],
   "source": [
    "# Download the twitter_samples dataset\n",
    "nltk.download('twitter_samples')\n",
    "\n",
    "# Import twitter_samples dataset\n",
    "from nltk.corpus import twitter_samples\n",
    "\n",
    "# Load positive and negative tweets\n",
    "positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "negative_tweets = twitter_samples.strings('negative_tweets.json')\n",
    "\n",
    "# Creating labelled data\n",
    "documents = []\n",
    "\n",
    "# Adding positive tweets\n",
    "for tweet in positive_tweets:\n",
    "    documents.append((tweet, \"positive\"))\n",
    "\n",
    "# Adding negative tweets\n",
    "for tweet in negative_tweets:\n",
    "    documents.append((tweet, \"negative\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cd6b16fc-e0bd-4718-89f8-87a5c6c88b9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split the dataset into the text and labels\n",
    "texts, labels = zip(*documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6b5e4a8c-f47b-4fd3-9910-6cf81734555c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(texts, labels, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d9429679-4088-4c7b-9525-b0008a6b9f28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Begin text vectorization\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 3), min_df=5, max_df=0.8)\n",
    "\n",
    "# Fit and transform the training data\n",
    "train_vectors = vectorizer.fit_transform(train_texts)\n",
    "\n",
    "# Transform the test data\n",
    "test_vectors = vectorizer.transform(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "68043053-fb22-4b62-bfcb-23ab6d954309",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentiment predicted by the model is: positive\n",
      "The sentiment predicted by the model is: positive\n",
      "The sentiment predicted by the model is: negative\n",
      "The sentiment predicted by the model is: negative\n",
      "The sentiment predicted by the model is: negative\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Logistic Regression classifier\n",
    "logistic_classifier = LogisticRegression()\n",
    "\n",
    "# Train the classifier\n",
    "logistic_classifier.fit(train_vectors, train_labels)\n",
    "\n",
    "# Predict sentiments for test data using the trained classifier\n",
    "logistic_predictions = logistic_classifier.predict(test_vectors)\n",
    "\n",
    "# Test your results with the sample tweets below\n",
    "sample_tweets = [\n",
    "    \"Absolutely loving the new update! Everything runs so smoothly and efficiently now. Great job! 👍\",\n",
    "    \"Had an amazing time at the beach today with friends. The weather was perfect! ☀️ #blessed\",\n",
    "    \"Extremely disappointed with the service at the restaurant tonight. Waited over an hour and still got the order wrong. 😡\",\n",
    "    \"Feeling really let down by the season finale. It was so rushed and left too many unanswered questions. 😞 #TVShow\",\n",
    "    \"My phone keeps crashing after the latest update. So frustrating dealing with these glitches! 😠\",\n",
    "]\n",
    "\n",
    "# Test the function\n",
    "for sentence in sample_tweets:\n",
    "    def logistic_predict_sentiment(new_text):\n",
    "        new_vector = vectorizer.transform([new_text])\n",
    "        pred = logistic_classifier.predict(new_vector)\n",
    "        return pred[0]\n",
    "\n",
    "    print(f\"The sentiment predicted by the model is: {logistic_predict_sentiment(sentence)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "webscraper",
   "language": "python",
   "name": "webscraper"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
